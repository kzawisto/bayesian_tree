{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "latter-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tropical-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-citation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "liked-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.stats as sst\n",
    "\n",
    "\n",
    "def get_edfs(x1,x2, sorter=None):\n",
    "    if sorter is None:\n",
    "        vals=np.concatenate([x1,x2])\n",
    "        sorter=np.argsort(vals)\n",
    "    edf1=np.concatenate([np.ones_like(x1)/x1.shape[0],np.zeros_like(x2)])[sorter]\n",
    "    edf2=np.concatenate([np.zeros_like(x1), np.ones_like(x2)/x2.shape[0]])[sorter]\n",
    "    return np.cumsum(edf1), np.cumsum(edf2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "grand-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.special as ssp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mechanical-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logbeta(i,j):\n",
    "    return ssp.loggamma(i) + ssp.loggamma(j)-ssp.loggamma(i+j)\n",
    "\n",
    "def logbinom(i,j):\n",
    "    \n",
    "    return ssp.loggamma(i) + ssp.loggamma(j)-ssp.loggamma(i+j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "above-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def logbinom(i,j):\n",
    "#     return ssp.loggamma(i+j+1) - ssp.loggamma(i+1)-ssp.loggamma(j+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "central-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "def loglik_edf(feature, target):\n",
    "    s=np.argsort(feature)\n",
    "    target_cl1_below=np.concatenate([[0],np.cumsum(target[s])])\n",
    "    target_cl0_below=np.concatenate([[0],np.cumsum(1-target[s])])\n",
    "\n",
    "    target_cl1_above=np.sum(target[s]) - target_cl1_below\n",
    "    target_cl0_above=np.sum(1-target[s]) - target_cl0_below\n",
    "    return target_cl1_below\n",
    "    # target_cl0_above+target_cl0_below\n",
    "    proba_below = (1+target_cl1_below)/ (target_cl0_below + target_cl1_below+2)\n",
    "    proba_above = (1+target_cl1_above)/ (target_cl0_above + target_cl1_above+2)\n",
    "\n",
    "\n",
    "    loglik = np.log(proba_below)* target_cl1_below + np.log(1-proba_below) * (target_cl0_below) +\\\n",
    "    np.log(proba_above)* target_cl1_above + np.log(1-proba_above) * (target_cl0_above)\n",
    "\n",
    "    edf = np.cumsum(np.exp(loglik - np.max(loglik)))\n",
    "    edf = edf /edf[-1]\n",
    "    return edf,feature[s], np.argmax(loglik),np.max(loglik)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "noticed-bruce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.083024303278316"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "august-public",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "conceptual-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "Splitpoint = namedtuple('Splitpoint',['stat', 'point','idxpoint','idx_feature','counts','total_stat'],\n",
    "                       defaults=[0.,0,0,0,0,0])\n",
    "\n",
    "\n",
    "def twosample_to_featuretarget(x1,x2):\n",
    "    return np.concatenate([x1,x2]),np.concatenate([np.zeros_like(x1),np.ones_like(x2)])\n",
    "    \n",
    "def featuretarget_to_twosample(ft,tar):\n",
    "    return ft[tar==0], ft[tar==1]\n",
    "\n",
    "def rate_split(feature, target):\n",
    "    s=np.argsort(feature)\n",
    "    x1,x2=featuretarget_to_twosample(feature,target)\n",
    "    target_cl1_below=np.concatenate([[0],np.cumsum(target[s])])\n",
    "    target_cl0_below=np.concatenate([[0],np.cumsum(1-target[s])])\n",
    "\n",
    "    target_cl1_above=np.sum(target[s]) - target_cl1_below\n",
    "    target_cl0_above=np.sum(1-target[s]) - target_cl0_below\n",
    "    proba_below = (1+target_cl1_below)/ (target_cl0_below + target_cl1_below+2)\n",
    "    proba_above = (1+target_cl1_above)/ (target_cl0_above + target_cl1_above+2)\n",
    "\n",
    "\n",
    "    loglik1 = np.log(proba_below)* target_cl1_below + np.log(1-proba_below) * (target_cl0_below) +\\\n",
    "        np.log(proba_above)* target_cl1_above + np.log(1-proba_above) * (target_cl0_above)\n",
    "\n",
    "    ev=logbeta(target_cl0_below+1, target_cl1_below+1)+logbeta(target_cl0_above+1, target_cl1_above+1)\n",
    "    evidence1=ssp.logsumexp(\n",
    "    logbeta(target_cl0_below+1, target_cl1_below+1)+logbeta(target_cl0_above+1, target_cl1_above+1)\n",
    "    )- np.log(target.shape[0])\n",
    "    \n",
    "\n",
    "    split_point=0\n",
    "    evidence=-1e300\n",
    "    if len(feature) > 0:\n",
    "        split_point=feature[s][np.argmax(ev)]\n",
    "        evidence=evidence1\n",
    "    return loglik1,evidence,s, Splitpoint(point=split_point,\n",
    "            counts=[int(np.sum(x1>=split_point)),int(np.sum(x2>=split_point)),len(x1),len(x2)])\n",
    "\n",
    "\n",
    "def rate_cat_split(cl1bin0, cl0bin0,cl1bin1, cl0bin1):\n",
    "    cl1=cl1bin0+cl1bin1\n",
    "    cl0=cl0bin0+cl0bin1\n",
    "    \n",
    "    proba0=(cl1+1)/(cl1+cl0+2)\n",
    "    evidence0=logbeta(cl1+1, cl0+1)\n",
    "    loglik0=(np.log(proba0) * cl1 + np.log(1-proba0) * cl0)\n",
    "    \n",
    "    posterior0= loglik0- evidence0\n",
    "    \n",
    "    probab0=(cl1bin0+1)/(cl1bin0+cl0bin0+2)\n",
    "    evidenceb0=logbeta(cl1bin0+1, cl0bin0+1)\n",
    "    loglikb0=(np.log(probab0) * cl1bin0 + np.log(1-probab0) * cl0bin0)\n",
    "    \n",
    "    probab1=(cl1bin1+1)/(cl1bin1+cl0bin1+2)\n",
    "    evidenceb1=logbeta(cl1bin1+1, cl0bin1+1)\n",
    "    loglikb1=(np.log(probab1) * cl1bin1 + np.log(1-probab1) * cl0bin1)\n",
    "    posterior1 = (loglikb1+loglikb0) - (evidenceb1+evidenceb0)\n",
    "    \n",
    "    return -evidence0+(evidenceb1+evidenceb0),  evidence0,(evidenceb1+evidenceb0)\n",
    "    \n",
    "    \n",
    "\n",
    "def rate_all_splits(features, target):\n",
    "    data=[]\n",
    "    proba0=(np.sum(target)+1)/(target.shape[0]+2)\n",
    "    evidence0=logbeta(np.sum(target)+1, np.sum(1-target)+1)\n",
    "    loglik0=(np.log(proba0) * np.sum(target) + np.log(1-proba0) * np.sum(1-target))\n",
    "    for i in range(features.shape[1]):\n",
    "        loglik1,evidence1,s,split = rate_split(features[:,i], target)\n",
    "        data.append(dict(i=i,loglik=loglik1, evidence=evidence1, split=split._replace(idx_feature=i,\n",
    "                stat=evidence1-evidence0)))\n",
    "#     logliks=[d['maxloglik'] for d in data]\n",
    "    evidence = [d['evidence'] for d in data]\n",
    "    maxevidence = np.max(evidence)\n",
    "    arg = np.argmax(evidence)\n",
    "    \n",
    "    total_evidence = ssp.logsumexp(evidence)-np.log(features.shape[1])\n",
    "    best_choice = data[arg]\n",
    "    \n",
    "    data= sorted(data,key=lambda x: x['evidence'])\n",
    "    \n",
    "    return total_evidence- evidence0, [d['split'] for d in data]\n",
    "\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## below some experiments at establishing distribution of evidence ration - seems \n",
    "## that adding log(sqrt(N*M/(N+M))) gives value that has fixed distribution\n",
    "\n",
    "## this not used yet in a tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "terminal-slovak",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.9288 2.1332\n",
      "20 0.9986 2.3061\n",
      "30 1.0218 2.6231\n",
      "50 1.0459 2.5258\n",
      "60 1.0499 2.5486\n",
      "70 1.0507 2.5943\n",
      "80 1.0540 2.3630\n",
      "90 1.0543 2.4317\n",
      "100 1.0574 2.5103\n",
      "120 1.0596 2.4320\n",
      "140 1.0614 2.3936\n",
      "160 1.0648 2.5820\n",
      "200 1.0653 2.5602\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in [10,20,30,50,60,70,80,90,100,120,140,160,200]:\n",
    "    k1,k2=i,i\n",
    "    def test2():\n",
    "        x1=np.random.randint(0,2,k1)\n",
    "        x2=np.random.randint(0,2,k2)\n",
    "        return rate_cat_split(np.sum(x1),np.sum(1-x1),np.sum(x2),np.sum(1-x2))\n",
    "\n",
    "    sample3=np.array([test2() for _ in range(200000)])\n",
    "    print (i,\"%.4f\" % np.mean(sample3[:,0]+np.log(np.sqrt((k1*k2)*2/(k2+k1)))),\n",
    "    \"%.4f\" %np.quantile(sample3[:,0]+np.log(np.sqrt((k1*k2)*2/(k2+k1))),0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "economic-marks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sample3[:,0]+np.log(np.sqrt((k1*k2)*2/(k2+k1))),bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "diverse-brother",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009896824611116316"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "italic-framework",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.5236660500595463,\n",
       " [Splitpoint(stat=-3.7666412197213504, point=-3.76625240735568, idxpoint=0, idx_feature=2, counts=[30000, 29991, 30000, 30000], total_stat=0),\n",
       "  Splitpoint(stat=-3.7079234071061364, point=3.796696497620582, idxpoint=0, idx_feature=1, counts=[2, 0, 30000, 30000], total_stat=0),\n",
       "  Splitpoint(stat=-3.198697379739315, point=2.9927841316439108, idxpoint=0, idx_feature=0, counts=[59, 28, 30000, 30000], total_stat=0)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1=np.random.randn(30000,3)-0.0\n",
    "X2=np.random.randn(30000,3)+0.0\n",
    "features=np.concatenate([X1,X2])#.reshape(-1,1)\n",
    "target= np.concatenate([np.zeros_like(X1[:,0]),np.ones_like(X2[:,0])])\n",
    "\n",
    "rate_all_splits(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "female-baker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-metabolism",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "coordinate-chambers",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41178.217796328536"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "whole-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import collections\n",
    "INode=namedtuple('Node', ['feature','threshold','lc','rc','counts'],defaults=[-1,0,None,None,None])\n",
    "\n",
    "def serializer(obj):\n",
    "    if isinstance(obj, list):\n",
    "        return obj\n",
    "    if isinstance(obj,float) or isinstance(obj,np.float64):\n",
    "        return round(obj,3)\n",
    "    elif hasattr(obj,'__dict__'):\n",
    "        return vars(obj)\n",
    "    else:\n",
    "        str(obj)\n",
    "\n",
    "\n",
    "SplitProposal=namedtuple('SplitProposal', ['node','fidx','split','side'])\n",
    "feature_use_per_path=5\n",
    "class Node(object):\n",
    "    def __init__(self, feature=-1, threshold=0,lc=None, rc=None,counts=None,options=None, \n",
    "                 pval_threshold=0.01,\n",
    "                feature_use_per_path=3\n",
    "                ):\n",
    "        self.feature=feature\n",
    "        self.threshold=threshold\n",
    "        self.lc=lc \n",
    "        self.rc=rc\n",
    "        self.counts=counts\n",
    "        self.options = options\n",
    "        self.pval_threshold=pval_threshold\n",
    "        self.feature_use_per_path=feature_use_per_path\n",
    "    @staticmethod\n",
    "    def initialize_node(X,y, feature_use_per_path=3, pval_threshold=1):\n",
    "\n",
    "        evidence, splits=rate_all_splits(X,y)\n",
    "        split=splits[-1]\n",
    "        return Node(split.idx_feature, split.point,counts=split.counts,feature_use_per_path=feature_use_per_path, pval_threshold=pval_threshold)\n",
    "    def __repr__(self):\n",
    "        import json\n",
    "        return json.dumps(self.__dict__, default=serializer)\n",
    "    def to_json(self):\n",
    "        import json\n",
    "        return json.dumps(self.__dict__, default=serializer)\n",
    "    \n",
    "    def options_to_consider(self, X: np.ndarray, y: np.ndarray, pruned_features=None):\n",
    "        if pruned_features==None:\n",
    "            pruned_features=[]\n",
    "        pruned_features = pruned_features+ [self.feature]\n",
    "        c=dict(collections.Counter(pruned_features))\n",
    "        feature = X[:,self.feature]\n",
    "        f = feature > self.threshold\n",
    "        total_splits=[]\n",
    "        changes_done=False\n",
    "        if self.lc is None and np.sum(~f)>2:\n",
    "            evidence, splits=rate_all_splits(X[~f], y[~f])\n",
    "            splits = [s for s in splits if s.idx_feature not in c or c[s.idx_feature] < self.feature_use_per_path]\n",
    "            if evidence > self.pval_threshold and len(splits)>0:\n",
    "                split=splits[-1]\n",
    "                self.lc = Node(split.idx_feature, split.point,counts=split.counts,feature_use_per_path=feature_use_per_path, pval_threshold=self.pval_threshold)\n",
    "                changes_done = True\n",
    "\n",
    "        else:\n",
    "            if np.sum(~f)>2:\n",
    "                changes_done = changes_done or self.lc.options_to_consider(X[~f],y[~f],pruned_features )\n",
    "        if self.rc is None and np.sum(f)>2:\n",
    "            \n",
    "            evidence, splits=rate_all_splits(X[f], y[f])\n",
    "            splits = [s for s in splits if s.idx_feature not in c or c[s.idx_feature] < self.feature_use_per_path]\n",
    "            if evidence > self.pval_threshold and len(splits)>0:\n",
    "                split=splits[-1]\n",
    "                self.rc = Node(split.idx_feature, split.point,counts=split.counts,feature_use_per_path=feature_use_per_path, pval_threshold=self.pval_threshold)\n",
    "                changes_done = True\n",
    "        else:\n",
    "            \n",
    "            if np.sum(f)>2:\n",
    "                changes_done = changes_done or self.rc.options_to_consider(X[f],y[f],pruned_features )\n",
    "        return changes_done\n",
    "            \n",
    "    def iterate_fit(self,X,y):\n",
    "        return self.options_to_consider(X,y)\n",
    "    def predict(self, features):\n",
    "        feature = features[:,self.feature]\n",
    "        c= self.counts\n",
    "        proba_right = (1+c[1])/(2+c[0]+c[1])\n",
    "        proba_left = (1+c[3]-c[1])/(2+c[3]-c[1]+c[2]-c[0])\n",
    "        f = feature > self.threshold\n",
    "        result = np.zeros(f.shape[0])\n",
    "        if self.rc is None:\n",
    "            result[f] = proba_right\n",
    "        else:\n",
    "            result[f]=self.rc.predict(features[f])\n",
    "            \n",
    "        if self.lc is None:\n",
    "            result[~f] = proba_left\n",
    "        else:\n",
    "            result[~f]=self.lc.predict(features[~f])\n",
    "        return result\n",
    "     \n",
    "class KSModel(object):\n",
    "    def __init__(self, feature_use_per_path=3, pval_threshold=0.01):\n",
    "        self.n=None\n",
    "        self.pval_threshold=pval_threshold\n",
    "        self.feature_use_per_path=feature_use_per_path\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        n=Node.initialize_node(X,y, feature_use_per_path=self.feature_use_per_path,pval_threshold=self.pval_threshold)\n",
    "        while n.iterate_fit(X,y):\n",
    "            \n",
    "            pass\n",
    "        self.n = n\n",
    "    def predict(self,X):\n",
    "        return self.n.predict(X)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "amazing-sherman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7857142857142857 0.7350970017636684\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "defensive-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_dataset(df, f,preproc=lambda x:x):\n",
    "    specs = [dict(max_depth=3),dict(max_depth=5),dict(max_depth=6), dict(max_depth=8),dict(min_samples_leaf=10),\n",
    "            dict(max_depth=5, criterion='entropy'),dict(min_samples_leaf=50),dict(min_weight_fraction_leaf=0.01),dict()\n",
    "            ]\n",
    "    specs = [dict(max_depth=3),dict(max_depth=5),dict(max_depth=6), dict(max_depth=8),dict(min_samples_leaf=10),\n",
    "            dict(max_depth=5, criterion='entropy'),dict(min_samples_leaf=50),dict(min_weight_fraction_leaf=0.01),dict(),\n",
    "             dict(min_samples_leaf=5),dict(min_samples_leaf=20),dict(min_samples_leaf=10,criterion='entropy')\n",
    "            ]\n",
    "    results = []\n",
    "    for i in range(100):\n",
    "        df2=df.sample(frac=1,replace=False)\n",
    "        df2=preproc(df2)\n",
    "    #     df2[f]=  (df2[f]=='g')*1\n",
    "        split = int(df2.shape[0]*0.8)\n",
    "        train=df2.iloc[0:split]\n",
    "        test=df2.iloc[split:]\n",
    "        for s in specs:\n",
    "            dec=DecisionTreeClassifier( **s)\n",
    "            dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "            p=dec.predict_proba(test.iloc[:,0:f].values)[:,1]\n",
    "            x1=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "            t1= np.mean(test.iloc[:,f].values==((p>0.5)*1))\n",
    "            results.append((str(s),x1,t1))\n",
    "\n",
    "        # dec=xgboost.XGBRFClassifier()\n",
    "        # dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "        # p=dec.predict_proba(test.iloc[:,0:f].values)[:,1]\n",
    "        # x3=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "\n",
    "\n",
    "        dec=KSModel(pval_threshold=-0.5)\n",
    "        dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "        p=dec.predict(test.iloc[:,0:f].values)\n",
    "        x2=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "        t1= np.mean(test.iloc[:,f].values==((p>0.5)*1))\n",
    "        results.append((\"bayes-0.5\",x2,t1))\n",
    "\n",
    "        dec=KSModel(pval_threshold=0)\n",
    "        dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "        p=dec.predict(test.iloc[:,0:f].values)\n",
    "        x2=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "        t1= np.mean(test.iloc[:,f].values==((p>0.5)*1))\n",
    "        results.append((\"bayes-0\",x2,t1))\n",
    "\n",
    "        dec=KSModel(pval_threshold=0.5)\n",
    "        dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "        p=dec.predict(test.iloc[:,0:f].values)\n",
    "        x2=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "        t1= np.mean(test.iloc[:,f].values==((p>0.5)*1))\n",
    "        results.append((\"bayes+0.5\",x2,t1))\n",
    "        \n",
    "    s=pd.Series([r[1] for r in results],[r[0]for  r in results])\n",
    "    print(\"ROC\")\n",
    "    print(s.groupby(s.index).mean())\n",
    "    \n",
    "    print(\"accuracy\")\n",
    "    s=pd.Series([r[2] for r in results],[r[0]for  r in results])\n",
    "    print(s.groupby(s.index).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-conclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HABERMAN\n",
      "ROC\n",
      "bayes+0.5                                           0.632007\n",
      "bayes-0                                             0.633217\n",
      "bayes-0.5                                           0.630940\n",
      "{'max_depth': 3}                                    0.629607\n",
      "{'max_depth': 5, 'criterion': 'entropy'}            0.617487\n",
      "{'max_depth': 5}                                    0.609307\n",
      "{'max_depth': 6}                                    0.608853\n",
      "{'max_depth': 8}                                    0.576767\n",
      "{'min_samples_leaf': 10, 'criterion': 'entropy'}    0.650541\n",
      "{'min_samples_leaf': 10}                            0.651819\n",
      "{'min_samples_leaf': 20}                            0.657042\n",
      "{'min_samples_leaf': 50}                            0.659467\n",
      "{'min_samples_leaf': 5}                             0.619498\n",
      "{'min_weight_fraction_leaf': 0.01}                  0.601996\n",
      "{}                                                  0.554989\n",
      "dtype: float64\n",
      "accuracy\n",
      "bayes+0.5                                           0.718871\n",
      "bayes-0                                             0.720161\n",
      "bayes-0.5                                           0.728065\n",
      "{'max_depth': 3}                                    0.735968\n",
      "{'max_depth': 5, 'criterion': 'entropy'}            0.716774\n",
      "{'max_depth': 5}                                    0.714839\n",
      "{'max_depth': 6}                                    0.709032\n",
      "{'max_depth': 8}                                    0.678548\n",
      "{'min_samples_leaf': 10, 'criterion': 'entropy'}    0.714677\n",
      "{'min_samples_leaf': 10}                            0.717419\n",
      "{'min_samples_leaf': 20}                            0.733548\n",
      "{'min_samples_leaf': 50}                            0.718871\n",
      "{'min_samples_leaf': 5}                             0.685161\n",
      "{'min_weight_fraction_leaf': 0.01}                  0.669677\n",
      "{}                                                  0.653065\n",
      "dtype: float64\n",
      "DIABETES\n",
      "ROC\n",
      "bayes+0.5                                           0.791602\n",
      "bayes-0                                             0.792689\n",
      "bayes-0.5                                           0.782622\n",
      "{'max_depth': 3}                                    0.780009\n",
      "{'max_depth': 5, 'criterion': 'entropy'}            0.775210\n",
      "{'max_depth': 5}                                    0.772476\n",
      "{'max_depth': 6}                                    0.755224\n",
      "{'max_depth': 8}                                    0.712080\n",
      "{'min_samples_leaf': 10, 'criterion': 'entropy'}    0.773916\n",
      "{'min_samples_leaf': 10}                            0.768002\n",
      "{'min_samples_leaf': 20}                            0.802683\n",
      "{'min_samples_leaf': 50}                            0.804147\n",
      "{'min_samples_leaf': 5}                             0.739326\n",
      "{'min_weight_fraction_leaf': 0.01}                  0.757711\n",
      "{}                                                  0.671829\n",
      "dtype: float64\n",
      "accuracy\n",
      "bayes+0.5                                           0.741039\n",
      "bayes-0                                             0.742922\n",
      "bayes-0.5                                           0.726558\n",
      "{'max_depth': 3}                                    0.739740\n",
      "{'max_depth': 5, 'criterion': 'entropy'}            0.736234\n",
      "{'max_depth': 5}                                    0.739545\n",
      "{'max_depth': 6}                                    0.727727\n",
      "{'max_depth': 8}                                    0.708896\n",
      "{'min_samples_leaf': 10, 'criterion': 'entropy'}    0.740649\n",
      "{'min_samples_leaf': 10}                            0.733506\n",
      "{'min_samples_leaf': 20}                            0.749026\n",
      "{'min_samples_leaf': 50}                            0.749675\n",
      "{'min_samples_leaf': 5}                             0.715455\n",
      "{'min_weight_fraction_leaf': 0.01}                  0.724805\n",
      "{}                                                  0.700649\n",
      "dtype: float64\n",
      "SONAR\n",
      "ROC\n",
      "bayes+0.5                                           0.759533\n",
      "bayes-0                                             0.772443\n",
      "bayes-0.5                                           0.780851\n",
      "{'max_depth': 3}                                    0.717623\n",
      "{'max_depth': 5, 'criterion': 'entropy'}            0.749003\n",
      "{'max_depth': 5}                                    0.714529\n",
      "{'max_depth': 6}                                    0.714085\n",
      "{'max_depth': 8}                                    0.711949\n",
      "{'min_samples_leaf': 10, 'criterion': 'entropy'}    0.793494\n",
      "{'min_samples_leaf': 10}                            0.764713\n",
      "{'min_samples_leaf': 20}                            0.766140\n",
      "{'min_samples_leaf': 50}                            0.722931\n",
      "{'min_samples_leaf': 5}                             0.743293\n",
      "{'min_weight_fraction_leaf': 0.01}                  0.731187\n",
      "{}                                                  0.711978\n",
      "dtype: float64\n",
      "accuracy\n",
      "bayes+0.5                                           0.702857\n",
      "bayes-0                                             0.721905\n",
      "bayes-0.5                                           0.715476\n",
      "{'max_depth': 3}                                    0.698095\n",
      "{'max_depth': 5, 'criterion': 'entropy'}            0.729048\n",
      "{'max_depth': 5}                                    0.714286\n",
      "{'max_depth': 6}                                    0.712857\n",
      "{'max_depth': 8}                                    0.711190\n",
      "{'min_samples_leaf': 10, 'criterion': 'entropy'}    0.732143\n",
      "{'min_samples_leaf': 10}                            0.704286\n",
      "{'min_samples_leaf': 20}                            0.677619\n",
      "{'min_samples_leaf': 50}                            0.708095\n",
      "{'min_samples_leaf': 5}                             0.704048\n",
      "{'min_weight_fraction_leaf': 0.01}                  0.717619\n",
      "{}                                                  0.710476\n",
      "dtype: float64\n",
      "BANKNOTE\n",
      "ROC\n",
      "bayes+0.5                                           0.990170\n",
      "bayes-0                                             0.990507\n",
      "bayes-0.5                                           0.990596\n",
      "{'max_depth': 3}                                    0.970975\n",
      "{'max_depth': 5, 'criterion': 'entropy'}            0.989176\n",
      "{'max_depth': 5}                                    0.987766\n",
      "{'max_depth': 6}                                    0.986498\n",
      "{'max_depth': 8}                                    0.985070\n",
      "{'min_samples_leaf': 10, 'criterion': 'entropy'}    0.990927\n",
      "{'min_samples_leaf': 10}                            0.988332\n",
      "{'min_samples_leaf': 20}                            0.986689\n",
      "{'min_samples_leaf': 50}                            0.971536\n",
      "{'min_samples_leaf': 5}                             0.988773\n",
      "{'min_weight_fraction_leaf': 0.01}                  0.988088\n",
      "{}                                                  0.985271\n",
      "dtype: float64\n",
      "accuracy\n",
      "bayes+0.5                                           0.984509\n",
      "bayes-0                                             0.980691\n",
      "bayes-0.5                                           0.972473\n",
      "{'max_depth': 3}                                    0.936945\n",
      "{'max_depth': 5, 'criterion': 'entropy'}            0.982727\n",
      "{'max_depth': 5}                                    0.973127\n",
      "{'max_depth': 6}                                    0.982836\n",
      "{'max_depth': 8}                                    0.985055\n",
      "{'min_samples_leaf': 10, 'criterion': 'entropy'}    0.981200\n",
      "{'min_samples_leaf': 10}                            0.974327\n",
      "{'min_samples_leaf': 20}                            0.951055\n",
      "{'min_samples_leaf': 50}                            0.906327\n",
      "{'min_samples_leaf': 5}                             0.978582\n",
      "{'min_weight_fraction_leaf': 0.01}                  0.971891\n",
      "{}                                                  0.985273\n",
      "dtype: float64\n",
      "IONOSPHERE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preproc_haberman(df2):\n",
    "    df2[3] = (df2[3]==2)*1\n",
    "    return df2\n",
    "\n",
    "def preproc_iono(df2):\n",
    "    f=34\n",
    "    df2[f]=  (df2[f]=='g')*1\n",
    "    return df2\n",
    "def preproc_sonar(df2):\n",
    "    f=60\n",
    "    df2[f]=  (df2[f]=='M')*1\n",
    "    return df2\n",
    "np.random.seed(0)\n",
    "print(\"HABERMAN\")\n",
    "test_dataset(pd.read_csv(\"/home/krystian/dane/data/haberman.data\",header=None),3, preproc_haberman)\n",
    "print(\"DIABETES\")\n",
    "test_dataset(pd.read_csv(\"/home/krystian/dane/data/pima-indians-diabetes.csv\",header=None),8)\n",
    "print(\"SONAR\")\n",
    "test_dataset(pd.read_csv(\"/home/krystian/dane/data/sonar.all-data\",header=None),60,preproc_sonar)\n",
    "print(\"BANKNOTE\")\n",
    "test_dataset(pd.read_csv(\"/home/krystian/dane/data/data_banknote_authentication.txt\",header=None),4)\n",
    "\n",
    "print(\"IONOSPHERE\")\n",
    "test_dataset(pd.read_csv(\"/home/krystian/dane/data/ionosphere.data\",header=None),34\n",
    "             ,preproc_iono)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-gothic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "painful-thinking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-appreciation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

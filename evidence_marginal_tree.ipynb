{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "latter-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tropical-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-citation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "liked-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.stats as sst\n",
    "\n",
    "\n",
    "def get_edfs(x1,x2, sorter=None):\n",
    "    if sorter is None:\n",
    "        vals=np.concatenate([x1,x2])\n",
    "        sorter=np.argsort(vals)\n",
    "    edf1=np.concatenate([np.ones_like(x1)/x1.shape[0],np.zeros_like(x2)])[sorter]\n",
    "    edf2=np.concatenate([np.zeros_like(x1), np.ones_like(x2)/x2.shape[0]])[sorter]\n",
    "    return np.cumsum(edf1), np.cumsum(edf2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "grand-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.special as ssp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mechanical-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logbeta(i,j):\n",
    "    return ssp.loggamma(i) + ssp.loggamma(j)-ssp.loggamma(i+j)\n",
    "\n",
    "def logbinom(i,j):\n",
    "    \n",
    "    return ssp.loggamma(i) + ssp.loggamma(j)-ssp.loggamma(i+j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "composed-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "logbeta(100,14)\n",
    "features= np.random.randn(300,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cooperative-feedback",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004975124378109453"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(85+115)/(85*115)\n",
    "ssp.binom(85+115,115)*ssp.beta(86,116)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# np.exp(np.log(ssp.binom(85+115,115))+ssp.loggamma(86)+ssp.loggamma(116)- ssp.loggamma(86+116))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "above-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ssp.gamma(11)/ssp.gamma(6)/ssp.gamma(6)-   ssp.binom(10,5)\n",
    "\n",
    "def logbinom(i,j):\n",
    "    return ssp.loggamma(i+j+1) - ssp.loggamma(i+1)-ssp.loggamma(j+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "central-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "def loglik_edf(feature, target):\n",
    "    s=np.argsort(feature)\n",
    "    target_cl1_below=np.concatenate([[0],np.cumsum(target[s])])\n",
    "    target_cl0_below=np.concatenate([[0],np.cumsum(1-target[s])])\n",
    "\n",
    "    target_cl1_above=np.sum(target[s]) - target_cl1_below\n",
    "    target_cl0_above=np.sum(1-target[s]) - target_cl0_below\n",
    "    return target_cl1_below\n",
    "    # target_cl0_above+target_cl0_below\n",
    "    proba_below = (1+target_cl1_below)/ (target_cl0_below + target_cl1_below+2)\n",
    "    proba_above = (1+target_cl1_above)/ (target_cl0_above + target_cl1_above+2)\n",
    "\n",
    "\n",
    "    loglik = np.log(proba_below)* target_cl1_below + np.log(1-proba_below) * (target_cl0_below) +\\\n",
    "    np.log(proba_above)* target_cl1_above + np.log(1-proba_above) * (target_cl0_above)\n",
    "\n",
    "    edf = np.cumsum(np.exp(loglik - np.max(loglik)))\n",
    "    edf = edf /edf[-1]\n",
    "    return edf,feature[s], np.argmax(loglik),np.max(loglik)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "noticed-bruce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.083024303278316"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=sst.norm(0,1).rvs(100)\n",
    "np.sum(x**2*sst.norm.pdf(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "august-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# target\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(X1.ravel(), alpha=0.4)\n",
    "# plt.hist(X2.ravel(),alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "conceptual-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "Splitpoint = namedtuple('Splitpoint',['stat', 'point','idxpoint','idx_feature','counts','total_stat'],\n",
    "                       defaults=[0.,0,0,0,0,0])\n",
    "\n",
    "\n",
    "def twosample_to_featuretarget(x1,x2):\n",
    "    return np.concatenate([x1,x2]),np.concatenate([np.zeros_like(x1),np.ones_like(x2)])\n",
    "    \n",
    "def featuretarget_to_twosample(ft,tar):\n",
    "    return ft[tar==0], ft[tar==1]\n",
    "\n",
    "def rate_split(feature, target):\n",
    "    s=np.argsort(feature)\n",
    "    x1,x2=featuretarget_to_twosample(feature,target)\n",
    "    target_cl1_below=np.concatenate([[0],np.cumsum(target[s])])\n",
    "    target_cl0_below=np.concatenate([[0],np.cumsum(1-target[s])])\n",
    "\n",
    "    target_cl1_above=np.sum(target[s]) - target_cl1_below\n",
    "    target_cl0_above=np.sum(1-target[s]) - target_cl0_below\n",
    "    proba_below = (1+target_cl1_below)/ (target_cl0_below + target_cl1_below+2)\n",
    "    proba_above = (1+target_cl1_above)/ (target_cl0_above + target_cl1_above+2)\n",
    "\n",
    "\n",
    "    loglik1 = np.log(proba_below)* target_cl1_below + np.log(1-proba_below) * (target_cl0_below) +\\\n",
    "        np.log(proba_above)* target_cl1_above + np.log(1-proba_above) * (target_cl0_above)\n",
    "\n",
    "    ev=logbeta(target_cl0_below+1, target_cl1_below+1)+logbeta(target_cl0_above+1, target_cl1_above+1)\n",
    "    evidence1=ssp.logsumexp(\n",
    "    logbeta(target_cl0_below+1, target_cl1_below+1)+logbeta(target_cl0_above+1, target_cl1_above+1)\n",
    "    )- np.log(target.shape[0])\n",
    "    \n",
    "\n",
    "    split_point=0\n",
    "    evidence=-1e300\n",
    "    if len(feature) > 0:\n",
    "        split_point=feature[s][np.argmax(ev)]\n",
    "        evidence=evidence1\n",
    "    return loglik1,evidence,s, Splitpoint(point=split_point,\n",
    "            counts=[int(np.sum(x1>=split_point)),int(np.sum(x2>=split_point)),len(x1),len(x2)])\n",
    "\n",
    "\n",
    "def rate_cat_split(cl1bin0, cl0bin0,cl1bin1, cl0bin1):\n",
    "    cl1=cl1bin0+cl1bin1\n",
    "    cl0=cl0bin0+cl0bin1\n",
    "    \n",
    "    proba0=(cl1+1)/(cl1+cl0+2)\n",
    "    evidence0=logbeta(cl1+1, cl0+1)\n",
    "    loglik0=(np.log(proba0) * cl1 + np.log(1-proba0) * cl0)\n",
    "    \n",
    "    posterior0= loglik0- evidence0\n",
    "    \n",
    "    probab0=(cl1bin0+1)/(cl1bin0+cl0bin0+2)\n",
    "    evidenceb0=logbeta(cl1bin0+1, cl0bin0+1)\n",
    "    loglikb0=(np.log(probab0) * cl1bin0 + np.log(1-probab0) * cl0bin0)\n",
    "    \n",
    "    probab1=(cl1bin1+1)/(cl1bin1+cl0bin1+2)\n",
    "    evidenceb1=logbeta(cl1bin1+1, cl0bin1+1)\n",
    "    loglikb1=(np.log(probab1) * cl1bin1 + np.log(1-probab1) * cl0bin1)\n",
    "    posterior1 = (loglikb1+loglikb0) - (evidenceb1+evidenceb0)\n",
    "    \n",
    "    return -evidence0+(evidenceb1+evidenceb0),  evidence0,(evidenceb1+evidenceb0)\n",
    "    \n",
    "    \n",
    "\n",
    "def rate_all_splits(features, target):\n",
    "    data=[]\n",
    "    proba0=(np.sum(target)+1)/(target.shape[0]+2)\n",
    "    evidence0=logbeta(np.sum(target)+1, np.sum(1-target)+1)\n",
    "    loglik0=(np.log(proba0) * np.sum(target) + np.log(1-proba0) * np.sum(1-target))\n",
    "    for i in range(features.shape[1]):\n",
    "        loglik1,evidence1,s,split = rate_split(features[:,i], target)\n",
    "        data.append(dict(i=i,loglik=loglik1, evidence=evidence1, split=split._replace(idx_feature=i,\n",
    "                stat=evidence1-evidence0)))\n",
    "#     logliks=[d['maxloglik'] for d in data]\n",
    "    evidence = [d['evidence'] for d in data]\n",
    "    maxevidence = np.max(evidence)\n",
    "    arg = np.argmax(evidence)\n",
    "    \n",
    "    total_evidence = ssp.logsumexp(evidence)-np.log(features.shape[1])\n",
    "    best_choice = data[arg]\n",
    "    \n",
    "    data= sorted(data,key=lambda x: x['evidence'])\n",
    "    \n",
    "    return total_evidence- evidence0, [d['split'] for d in data]\n",
    "\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "thermal-venue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 s, sys: 59.9 ms, total: 23 s\n",
      "Wall time: 23.1 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test():\n",
    "    x1=np.random.randint(0,2,5000)\n",
    "    x2=np.random.randint(0,2,5000)\n",
    "    return rate_cat_split(np.sum(x1),np.sum(1-x1),np.sum(x2),np.sum(1-x2))\n",
    "\n",
    "sample=np.array([test() for _ in range(200000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "confidential-hebrew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.41271757e+00, -6.93565908e+03, -6.93907179e+03],\n",
       "       [-3.68569200e+00, -6.93549849e+03, -6.93918418e+03],\n",
       "       [-3.66228216e+00, -6.93563348e+03, -6.93929576e+03],\n",
       "       ...,\n",
       "       [-2.91779028e+00, -6.93584406e+03, -6.93876185e+03],\n",
       "       [-3.68565710e+00, -6.93584806e+03, -6.93953372e+03],\n",
       "       [-3.66656573e+00, -6.93475613e+03, -6.93842269e+03]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cognitive-substance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.40842997e+00, 1.21462288e+00, 9.70328341e-01, 6.53034105e-01,\n",
       "        4.90644040e-01, 4.43331237e-01, 3.14945720e-01, 2.86861389e-01,\n",
       "        2.59706678e-01, 2.35242974e-01, 1.60824388e-01, 1.98987765e-01,\n",
       "        1.33278257e-01, 1.20018930e-01, 1.05047143e-01, 9.91758545e-02,\n",
       "        8.64058012e-02, 5.32819465e-02, 7.32443287e-02, 6.48777420e-02,\n",
       "        3.69891199e-02, 4.78510043e-02, 3.28302903e-02, 2.80843318e-02,\n",
       "        3.84569421e-02, 2.42190666e-02, 1.83477777e-02, 1.80052859e-02,\n",
       "        1.79074311e-02, 1.54121333e-02, 1.48250044e-02, 1.18404326e-02,\n",
       "        1.13511585e-02, 1.10086666e-02, 8.51336886e-03, 8.95371553e-03,\n",
       "        7.63267553e-03, 6.65412739e-03, 6.60519998e-03, 2.44637036e-03,\n",
       "        6.11592591e-03, 4.15882962e-03, 4.55024887e-03, 1.76138666e-03,\n",
       "        3.91419258e-03, 3.32706369e-03, 2.10387851e-03, 2.54422518e-03,\n",
       "        2.10387851e-03, 1.17425777e-03, 1.66353185e-03, 7.33911109e-04,\n",
       "        1.32104000e-03, 1.46782222e-03, 7.82838516e-04, 1.12533037e-03,\n",
       "        3.91419258e-04, 1.07640296e-03, 4.40346665e-04, 8.31765923e-04,\n",
       "        4.40346665e-04, 2.44637036e-04, 2.93564443e-04, 2.93564443e-04,\n",
       "        4.40346665e-04, 2.93564443e-04, 3.42491851e-04, 4.89274072e-05,\n",
       "        4.89274072e-05, 2.93564443e-04, 9.78548145e-05, 0.00000000e+00,\n",
       "        9.78548145e-05, 4.89274072e-05, 0.00000000e+00, 9.78548145e-05,\n",
       "        0.00000000e+00, 4.89274072e-05, 0.00000000e+00, 1.95709629e-04,\n",
       "        9.78548145e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.89274072e-05, 4.89274072e-05,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.89274072e-05,\n",
       "        0.00000000e+00, 4.89274072e-05, 0.00000000e+00, 4.89274072e-05]),\n",
       " array([-3.68713406, -3.58494185, -3.48274964, -3.38055742, -3.27836521,\n",
       "        -3.176173  , -3.07398079, -2.97178857, -2.86959636, -2.76740415,\n",
       "        -2.66521194, -2.56301972, -2.46082751, -2.3586353 , -2.25644309,\n",
       "        -2.15425087, -2.05205866, -1.94986645, -1.84767424, -1.74548202,\n",
       "        -1.64328981, -1.5410976 , -1.43890539, -1.33671317, -1.23452096,\n",
       "        -1.13232875, -1.03013654, -0.92794432, -0.82575211, -0.7235599 ,\n",
       "        -0.62136769, -0.51917547, -0.41698326, -0.31479105, -0.21259884,\n",
       "        -0.11040662, -0.00821441,  0.0939778 ,  0.19617002,  0.29836223,\n",
       "         0.40055444,  0.50274665,  0.60493887,  0.70713108,  0.80932329,\n",
       "         0.9115155 ,  1.01370772,  1.11589993,  1.21809214,  1.32028435,\n",
       "         1.42247657,  1.52466878,  1.62686099,  1.7290532 ,  1.83124542,\n",
       "         1.93343763,  2.03562984,  2.13782205,  2.24001427,  2.34220648,\n",
       "         2.44439869,  2.5465909 ,  2.64878312,  2.75097533,  2.85316754,\n",
       "         2.95535975,  3.05755197,  3.15974418,  3.26193639,  3.3641286 ,\n",
       "         3.46632082,  3.56851303,  3.67070524,  3.77289745,  3.87508967,\n",
       "         3.97728188,  4.07947409,  4.1816663 ,  4.28385852,  4.38605073,\n",
       "         4.48824294,  4.59043515,  4.69262737,  4.79481958,  4.89701179,\n",
       "         4.999204  ,  5.10139622,  5.20358843,  5.30578064,  5.40797285,\n",
       "         5.51016507,  5.61235728,  5.71454949,  5.8167417 ,  5.91893392,\n",
       "         6.02112613,  6.12331834,  6.22551055,  6.32770277,  6.42989498,\n",
       "         6.53208719]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPV0lEQVR4nO3df6zddX3H8edrbRWjThJ7E0lbvSYjWdSJ6E3FkGxEx1KV0CxihGUqbqbTgULCtiBmqPylWaJTMZIGmOAIatC5qmWuiyTKH1Ruu4K2BdMYNkpYuNIJEh2m7r0/7hd2vZ5zz7m359xz++nzkZz0++Nzv9/3N819nc/9nM/3e1JVSJJOfr816QIkSaNhoEtSIwx0SWqEgS5JjTDQJakR6yd14o0bN9b09PSkTi9JJ6V9+/b9pKqmeu2bWKBPT08zOzs7qdNL0kkpyX/02zdwyCXJaUm+n+S+JAeTfKxHm0uTzCU50L3ee6JFS5KWZ5ge+tPAG6vqqSQbgLuT3FlV9yxq9+Wqunz0JUqShjEw0Gv+VtKnutUN3cvbSyVpjRlqlkuSdUkOAI8Be6pqb49mb0tyf5I7kmzpc5wdSWaTzM7Nza28aknSbxgq0KvqV1X1GmAzsDXJqxY1+QYwXVWvBvYAt/Q5zs6qmqmqmampnh/SSpJWaFnz0Kvqp8BdwLZF2x+vqqe71RuB142kOknS0IaZ5TKV5PRu+XnA+cADi9qcsWD1QuDwCGuUJA1hmFkuZwC3JFnH/BvAV6rqm0muA2arahfwwSQXAseBY8Cl4ypYktRbJvU89JmZmfLGIklaniT7qmqm176J3Sl6Iqav/tazyw99/K0TrESS1g4fziVJjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYMDPQkpyX5fpL7khxM8rEebZ6b5MtJjiTZm2R6LNVKkvoapof+NPDGqjoLeA2wLck5i9r8OfDfVfU7wKeAT4y0SknSQAMDveY91a1u6F61qNl24JZu+Q7gTUkysiolSQMNNYaeZF2SA8BjwJ6q2ruoySbgYYCqOg48Abx4hHVKkgYYKtCr6ldV9RpgM7A1yatWcrIkO5LMJpmdm5tbySEkSX0sa5ZLVf0UuAvYtmjXI8AWgCTrgRcBj/f4+Z1VNVNVM1NTUysqWJLU2zCzXKaSnN4tPw84H3hgUbNdwLu75YuA71TV4nF2SdIYrR+izRnALUnWMf8G8JWq+maS64DZqtoF3AR8MckR4Bhw8dgqliT1NDDQq+p+4Owe269dsPw/wNtHW5okaTm8U1SSGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDViYKAn2ZLkriSHkhxMckWPNucleSLJge517XjKlST1s36INseBq6pqf5IXAvuS7KmqQ4vafa+qLhh9iZKkYQzsoVfVo1W1v1v+GXAY2DTuwiRJy7OsMfQk08DZwN4eu9+Q5L4kdyZ5ZZ+f35FkNsns3Nzc8quVJPU1dKAneQHwVeDKqnpy0e79wMuq6izgs8DXex2jqnZW1UxVzUxNTa2wZElSL0MFepINzIf5bVX1tcX7q+rJqnqqW94NbEiycaSVSpKWNMwslwA3AYer6pN92ryka0eSrd1xHx9loZKkpQ0zy+Vc4J3AD5Ic6LZdA7wUoKpuAC4C3p/kOPAL4OKqqtGXK0nqZ2CgV9XdQAa0uR64flRFSZKWzztFJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhoxMNCTbElyV5JDSQ4muaJHmyT5TJIjSe5P8trxlCtJ6mf9EG2OA1dV1f4kLwT2JdlTVYcWtHkzcGb3ej3w+e5fSdIqGdhDr6pHq2p/t/wz4DCwaVGz7cCtNe8e4PQkZ4y8WklSX8saQ08yDZwN7F20axPw8IL1o/xm6JNkR5LZJLNzc3PLLFWStJShAz3JC4CvAldW1ZMrOVlV7ayqmaqamZqaWskhJEl9DBXoSTYwH+a3VdXXejR5BNiyYH1zt02StEqGmeUS4CbgcFV9sk+zXcC7utku5wBPVNWjI6xTkjTAMLNczgXeCfwgyYFu2zXASwGq6gZgN/AW4Ajwc+A9I69UkrSkgYFeVXcDGdCmgMtGVZQkafm8U1SSGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDViYKAnuTnJY0l+2Gf/eUmeSHKge107+jIlSYOsH6LNF4DrgVuXaPO9qrpgJBVJklZkYA+9qr4LHFuFWiRJJ2BUY+hvSHJfkjuTvLJfoyQ7kswmmZ2bmxvRqSVJMJpA3w+8rKrOAj4LfL1fw6raWVUzVTUzNTU1glNLkp5xwoFeVU9W1VPd8m5gQ5KNJ1yZJGlZTjjQk7wkSbrlrd0xHz/R40qSlmfgLJcktwPnARuTHAU+AmwAqKobgIuA9yc5DvwCuLiqamwVS5J6GhjoVXXJgP3XMz+tUZI0Qd4pKkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNWKYr6Bb06av/tavrT/08bdOqBJJmix76JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1IiBgZ7k5iSPJflhn/1J8pkkR5Lcn+S1oy9TkjTIMD30LwDbltj/ZuDM7rUD+PyJlyVJWq6BgV5V3wWOLdFkO3BrzbsHOD3JGaMqUJI0nFGMoW8CHl6wfrTb9huS7Egym2R2bm5uBKeWJD1jVT8UraqdVTVTVTNTU1OreWpJat4oHp/7CLBlwfrmbttELHycro/SlXQqGUUPfRfwrm62yznAE1X16AiOK0lahoE99CS3A+cBG5McBT4CbACoqhuA3cBbgCPAz4H3jKtYSVJ/AwO9qi4ZsL+Ay0ZWkSRpRbxTVJIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEaM4ivo1iy/jk7SqcQeuiQ1wkCXpEYY6JLUCANdkhphoEtSI4YK9CTbkjyY5EiSq3vsvzTJXJID3eu9oy9VkrSUgdMWk6wDPgecDxwF7k2yq6oOLWr65aq6fAw1SpKGMEwPfStwpKp+XFW/BL4EbB9vWZKk5Rom0DcBDy9YP9ptW+xtSe5PckeSLb0OlGRHktkks3NzcysoV5LUz6juFP0GcHtVPZ3kL4BbgDcublRVO4GdADMzMzWicw/Fu0YltW6YHvojwMIe9+Zu27Oq6vGqerpbvRF43WjKkyQNa5hAvxc4M8nLkzwHuBjYtbBBkjMWrF4IHB5diZKkYQwccqmq40kuB74NrANurqqDSa4DZqtqF/DBJBcCx4FjwKVjrPmEOfwiqUVDjaFX1W5g96Jt1y5Y/hDwodGWJklaDu8UlaRGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY1o+kuih+GcdEmtOOUDfSHDXdLJzCEXSWqEPfQ+7K1LOtnYQ5ekRthDH4K9dUknA3voktQIe+gnwJ67pLXEHrokNcIe+jIt7JVL0lpiD12SGmEPfUQcT5c0aQb6GPQbljHoJY2Tgb6K7MVLGicDfUL6hbuhL2mlDPQ1zHCXtBxDBXqSbcCngXXAjVX18UX7nwvcCrwOeBx4R1U9NNpS27XcqZDDBP3iY/qGILUvVbV0g2Qd8CPgfOAocC9wSVUdWtDmL4FXV9X7klwM/HFVvWOp487MzNTs7OyKinYu+Ikx3KWTV5J9VTXTa98wPfStwJGq+nF3sC8B24FDC9psBz7aLd8BXJ8kNejdQhOxlt8Q/TxBWrlhAn0T8PCC9aPA6/u1qarjSZ4AXgz8ZGGjJDuAHd3qU0ke7HG+jYt/rnGn0vUOvNZ8Ynnb1zj/b9s1yet9Wb8dq/qhaFXtBHYu1SbJbL8/J1p0Kl3vqXStcGpd76l0rbB2r3eYW/8fAbYsWN/cbevZJsl64EXMfzgqSVolwwT6vcCZSV6e5DnAxcCuRW12Ae/uli8CvuP4uSStroFDLt2Y+OXAt5mftnhzVR1Mch0wW1W7gJuALyY5AhxjPvRXaskhmQadStd7Kl0rnFrXeypdK6zR6x04bVGSdHLw8bmS1AgDXZIasaYDPclVSSrJxknXMi5J/i7JA0nuT/JPSU6fdE3jkGRbkgeTHEly9aTrGZckW5LcleRQkoNJrph0Tashybok/57km5OuZZySnJ7kju539nCSN0y6poXWbKAn2QL8EfCfk65lzPYAr6qqVzP/iIUPTbiekeseH/E54M3AK4BLkrxislWNzXHgqqp6BXAOcFnD17rQFcDhSRexCj4N/EtV/S5wFmvsmtdsoAOfAv4GaPpT26r616o63q3ew/w8/9Y8+/iIqvol8MzjI5pTVY9W1f5u+WfM/8JvmmxV45VkM/BW4MZJ1zJOSV4E/D7zs/qoql9W1U8nWtQiazLQk2wHHqmq+yZdyyr7M+DOSRcxBr0eH9F0yAEkmQbOBvZOuJRx+3vmO1//O+E6xu3lwBzwD93w0o1Jnj/pohaa2PPQk/wb8JIeuz4MXMP8cEsTlrrWqvrnrs2Hmf9z/bbVrE3jkeQFwFeBK6vqyUnXMy5JLgAeq6p9Sc6bcDnjth54LfCBqtqb5NPA1cDfTras/zexQK+qP+y1PcnvMf9OeF8SmB+C2J9ka1X91yqWODL9rvUZSS4FLgDe1OgdtsM8PqIZSTYwH+a3VdXXJl3PmJ0LXJjkLcBpwG8n+ceq+tMJ1zUOR4GjVfXMX1x3MB/oa8aav7EoyUPATFU1+SS37stDPgn8QVXNTbqeceie7/Mj4E3MB/m9wJ9U1cGJFjYGme+F3AIcq6orJ1zOqup66H9VVRdMuJSxSfI94L1V9WCSjwLPr6q/nnBZz/Ir6CbveuC5wJ7uL5J7qup9ky1ptPo9PmLCZY3LucA7gR8kOdBtu6aqdk+uJI3QB4Dbuuda/Rh4z4Tr+TVrvocuSRrOmpzlIklaPgNdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNeL/ABxPMr8vGAxoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(sample[:,0],bins=100,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "oriental-andorra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0023366666666666666"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sample>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ceramic-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test2():\n",
    "    x1=np.random.randint(0,2,500)\n",
    "    x2=np.random.randint(0,2,500)\n",
    "    return rate_cat_split(np.sum(x1),np.sum(1-x1),np.sum(x2),np.sum(1-x2))\n",
    "\n",
    "sample2=np.array([test2() for _ in range(200000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "eight-cuisine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5714625346266677, 0.5633584005927768)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.min(sample[:,0])+np.log(5000)/2,np.min(sample2[:,0])+np.log(500)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "heated-coating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.622776601683793"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.sqrt((k1*k2)*2/(k2+k1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "intelligent-contractor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.9288 2.1332\n",
      "20 0.9986 2.3061\n",
      "30 1.0218 2.6231\n",
      "50 1.0459 2.5258\n",
      "60 1.0499 2.5486\n",
      "70 1.0507 2.5943\n",
      "80 1.0540 2.3630\n",
      "90 1.0543 2.4317\n",
      "100 1.0574 2.5103\n",
      "120 1.0596 2.4320\n",
      "140 1.0614 2.3936\n",
      "160 1.0648 2.5820\n",
      "200 1.0653 2.5602\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in [10,20,30,50,60,70,80,90,100,120,140,160,200]:\n",
    "    k1,k2=i,i\n",
    "    # k1,k2=10,1010101010101010\n",
    "    def test2():\n",
    "        x1=np.random.randint(0,2,k1)\n",
    "        x2=np.random.randint(0,2,k2)\n",
    "        return rate_cat_split(np.sum(x1),np.sum(1-x1),np.sum(x2),np.sum(1-x2))\n",
    "\n",
    "    sample3=np.array([test2() for _ in range(200000)])\n",
    "    print (i,\"%.4f\" % np.mean(sample3[:,0]+np.log(np.sqrt((k1*k2)*2/(k2+k1)))),\n",
    "    \"%.4f\" %np.quantile(sample3[:,0]+np.log(np.sqrt((k1*k2)*2/(k2+k1))),0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "endangered-proxy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([469., 193., 153., 101.,  88.,  98.,  67.,  74.,  50.,  51.,  44.,\n",
       "         45.,  37.,  38.,  45.,  36.,  30.,  30.,  23.,  23.,  16.,  14.,\n",
       "         15.,  17.,  12.,  10.,  14.,  13.,   9.,  20.,   6.,   6.,   7.,\n",
       "          5.,  10.,   8.,   5.,   4.,   7.,   7.,   2.,   6.,   8.,   2.,\n",
       "          4.,   2.,   1.,   8.,   5.,   3.,   1.,   7.,   1.,   3.,   3.,\n",
       "          4.,   3.,   2.,   1.,   0.,   3.,   1.,   3.,   3.,   1.,   2.,\n",
       "          0.,   3.,   3.,   0.,   1.,   2.,   0.,   0.,   1.,   1.,   0.,\n",
       "          0.,   2.,   1.,   1.,   0.,   1.,   0.,   0.,   1.,   0.,   0.,\n",
       "          0.,   1.,   0.,   1.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,\n",
       "          1.]),\n",
       " array([0.56471706, 0.6140289 , 0.66334074, 0.71265258, 0.76196442,\n",
       "        0.81127625, 0.86058809, 0.90989993, 0.95921177, 1.00852361,\n",
       "        1.05783544, 1.10714728, 1.15645912, 1.20577096, 1.2550828 ,\n",
       "        1.30439463, 1.35370647, 1.40301831, 1.45233015, 1.50164199,\n",
       "        1.55095382, 1.60026566, 1.6495775 , 1.69888934, 1.74820118,\n",
       "        1.79751301, 1.84682485, 1.89613669, 1.94544853, 1.99476037,\n",
       "        2.04407221, 2.09338404, 2.14269588, 2.19200772, 2.24131956,\n",
       "        2.2906314 , 2.33994323, 2.38925507, 2.43856691, 2.48787875,\n",
       "        2.53719059, 2.58650242, 2.63581426, 2.6851261 , 2.73443794,\n",
       "        2.78374978, 2.83306161, 2.88237345, 2.93168529, 2.98099713,\n",
       "        3.03030897, 3.0796208 , 3.12893264, 3.17824448, 3.22755632,\n",
       "        3.27686816, 3.32617999, 3.37549183, 3.42480367, 3.47411551,\n",
       "        3.52342735, 3.57273919, 3.62205102, 3.67136286, 3.7206747 ,\n",
       "        3.76998654, 3.81929838, 3.86861021, 3.91792205, 3.96723389,\n",
       "        4.01654573, 4.06585757, 4.1151694 , 4.16448124, 4.21379308,\n",
       "        4.26310492, 4.31241676, 4.36172859, 4.41104043, 4.46035227,\n",
       "        4.50966411, 4.55897595, 4.60828778, 4.65759962, 4.70691146,\n",
       "        4.7562233 , 4.80553514, 4.85484698, 4.90415881, 4.95347065,\n",
       "        5.00278249, 5.05209433, 5.10140617, 5.150718  , 5.20002984,\n",
       "        5.24934168, 5.29865352, 5.34796536, 5.39727719, 5.44658903,\n",
       "        5.49590087]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAANCklEQVR4nO3dbYilZ33H8e+vu4mRWF1NhrDsLp2AwSIFkzCkkZRSEmzzhMmLKCltXGRl30SIpGA3fdMKha5vjApFWLKhm1bUYCxZEmkbkhUJNImzedJkW9zKhuyyuqN50CAWov++mMsw2c7snJk5DzvXfD8wzP105lz3m++555r7zElVIUnqy+9MegCSpOEz7pLUIeMuSR0y7pLUIeMuSR3aPOkBAFx44YU1PT096WFI0rpy+PDhn1bV1GL7zoq4T09PMzs7O+lhSNK6kuSlpfY5LSNJHTLuktQh4y5JHTLuktQh4y5JHTLuktQh4y5JHTLuktQh4y5JHTor3qG6FtN7Hn5r+djeGyY4Ekk6e3jlLkkdMu6S1CHjLkkdMu6S1CHjLkkdMu6S1CHjLkkdMu6S1CHjLkkdMu6S1CHjLkkdMu6S1CHjLkkdMu6S1CHjLkkdMu6S1CHjLkkdMu6S1CHjLkkdMu6S1CHjLkkdMu6S1CHjLkkdMu6S1CHjLkkdMu6S1KGB455kU5JnkjzU1i9O8mSSo0m+keTctv0dbf1o2z89orFLkpawkiv3O4AjC9Y/D9xdVe8HXgV2te27gFfb9rvbcZKkMRoo7km2AzcA97T1AFcD32yHHABubss3tXXa/mva8ZKkMRn0yv2LwGeB37T1C4DXqurNtn4c2NaWtwEvA7T9r7fj3ybJ7iSzSWbn5uZWN3pJ0qKWjXuSG4FTVXV4mE9cVfuqaqaqZqampob5oyVpw9s8wDFXAR9Ncj1wHvBu4EvAliSb29X5duBEO/4EsAM4nmQz8B7gZ0MfuSRpScteuVfVXVW1vaqmgVuBx6rqL4BDwC3tsJ3Ag235YFun7X+sqmqoo5YkndFa7nP/a+DOJEeZn1Pf37bvBy5o2+8E9qxtiJKklRpkWuYtVfUd4Dtt+UfAFYsc8yvgY0MYmyRplXyHqiR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1aNm4JzkvyVNJnkvyQpLPte0XJ3kyydEk30hybtv+jrZ+tO2fHvE5SJJOM8iV+/8CV1fVh4BLgWuTXAl8Hri7qt4PvArsasfvAl5t2+9ux0mSxmjZuNe8N9rqOe2rgKuBb7btB4Cb2/JNbZ22/5okGdaAJUnLG2jOPcmmJM8Cp4BHgP8BXquqN9shx4FtbXkb8DJA2/86cMEiP3N3ktkks3Nzc2s6CUnS2w0U96r6dVVdCmwHrgB+f61PXFX7qmqmqmampqbW+uMkSQus6G6ZqnoNOAR8GNiSZHPbtR040ZZPADsA2v73AD8bxmAlSYMZ5G6ZqSRb2vI7gY8AR5iP/C3tsJ3Ag235YFun7X+sqmqIY5YkLWPz8oewFTiQZBPzLwb3V9VDSV4Evp7k74FngP3t+P3APyc5CrwC3DqCcUuSzmDZuFfV88Bli2z/EfPz76dv/xXwsaGMTpK0Kr5DVZI6ZNwlqUPGXZI6ZNwlqUPGXZI6ZNwlqUPGXZI6ZNwlqUPGXZI6ZNwlqUPGXZI6ZNwlqUPGXZI6ZNwlqUPGXZI6ZNwlqUPGXZI6ZNwlqUPGXZI6ZNwlqUPGXZI6ZNwlqUPGXZI6ZNwlqUPGXZI6ZNwlqUPGXZI6ZNwlqUPGXZI6ZNwlqUPGXZI6ZNwlqUPGXZI6ZNwlqUPGXZI6tGzck+xIcijJi0leSHJH2/6+JI8k+WH7/t62PUm+nORokueTXD7qk5Akvd0gV+5vAn9VVR8ErgRuT/JBYA/waFVdAjza1gGuAy5pX7uBrwx91JKkM1o27lV1sqqebsu/AI4A24CbgAPtsAPAzW35JuC+mvcEsCXJ1mEPXJK0tBXNuSeZBi4DngQuqqqTbdePgYva8jbg5QUPO962nf6zdieZTTI7Nze30nFLks5g4LgneRfwAPCZqvr5wn1VVUCt5Imral9VzVTVzNTU1EoeKklaxkBxT3IO82H/alV9q23+yW+nW9r3U237CWDHgodvb9skSWMyyN0yAfYDR6rqCwt2HQR2tuWdwIMLtn+i3TVzJfD6gukbSdIYbB7gmKuA24DvJ3m2bfsbYC9wf5JdwEvAx9u+bwPXA0eBXwKfHOaAz2R6z8NvLR/be8O4nlaSzjrLxr2qHgeyxO5rFjm+gNvXOC5J0hr4DlVJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6tAgH9axLvnBHZI2Mq/cJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDy8Y9yb1JTiX5wYJt70vySJIftu/vbduT5MtJjiZ5Psnloxy8JGlxg1y5/xNw7Wnb9gCPVtUlwKNtHeA64JL2tRv4ynCGKUlaiWXjXlXfBV45bfNNwIG2fAC4ecH2+2reE8CWJFuHNFZJ0oA2r/JxF1XVybb8Y+CitrwNeHnBccfbtpNM0PSeh99aPrb3hgmORJLGY81/UK2qAmqlj0uyO8lsktm5ubm1DkOStMBqr9x/kmRrVZ1s0y6n2vYTwI4Fx21v2/6fqtoH7AOYmZlZ8YvDsHhVL6lHq71yPwjsbMs7gQcXbP9Eu2vmSuD1BdM3kqQxWfbKPcnXgD8BLkxyHPhbYC9wf5JdwEvAx9vh3wauB44CvwQ+OYIxS5KWsWzcq+rPl9h1zSLHFnD7WgclSVqb1c65r1sL59glqVf++wFJ6pBxl6QOGXdJ6pBxl6QOGXdJ6tCGu1tmUL5zVdJ65pW7JHXIuEtSh5yWWcA3OEnqhVfuktQh4y5JHTLuktQh4y5JHTLuktQh4y5JHfJWyBXynauS1gPjPgDvf5e03jgtI0kd8sp9DZa6ol9qusYpHUnj4pW7JHXIuEtSh5yWGQH/ACtp0oz7hDj/LmmUnJaRpA4Zd0nqkNMyZ4GV3lIpScvxyl2SOmTcJalDTsucxZyukbRaxl3L8rZNaf0x7p0yyNLGZtzXoaXC7TtjJf2WcV/n1hL0Mz3Wq31pfTPuG8Akr+idHpImw7hrUaN4QRhF6NfyM33hUc9GEvck1wJfAjYB91TV3lE8j8ZvkOivJZSD3P7pbyLS8oYe9ySbgH8EPgIcB76X5GBVvTjs59LZaZD4jjrQK43wWt9TsNLzWemYBnlxG8d5av1IVQ33ByYfBv6uqv6srd8FUFX/sNRjZmZmanZ2dlXP5x0i6skofkNZ6QvDal4A1vKRk0tZakzD+hjLQV48R/WRmcP6DTDJ4aqaWXTfCOJ+C3BtVX2qrd8G/GFVffq043YDu9vqB4D/HupARuNC4KeTHsQEeN4bx0Y8Z1i/5/17VTW12I6J/UG1qvYB+yb1/KuRZHapV8meed4bx0Y8Z+jzvEfxj8NOADsWrG9v2yRJYzKKuH8PuCTJxUnOBW4FDo7geSRJSxj6tExVvZnk08C/M38r5L1V9cKwn2dC1tU00hB53hvHRjxn6PC8h/4HVUnS5PlhHZLUIeMuSR0y7gNIcm+SU0l+MOmxjEuSHUkOJXkxyQtJ7pj0mMYhyXlJnkryXDvvz016TOOUZFOSZ5I8NOmxjEuSY0m+n+TZJKt7N+VZyDn3AST5Y+AN4L6q+oNJj2cckmwFtlbV00l+FzgM3Nz7v5FIEuD8qnojyTnA48AdVfXEhIc2FknuBGaAd1fVjZMezzgkOQbMVNV6fBPTkrxyH0BVfRd4ZdLjGKeqOllVT7flXwBHgG2THdXo1bw32uo57WtDXAEl2Q7cANwz6bFo7Yy7lpVkGrgMeHLCQxmLNjXxLHAKeKSqNsR5A18EPgv8ZsLjGLcC/iPJ4fZvUbpg3HVGSd4FPAB8pqp+PunxjENV/bqqLmX+3dVXJOl+Ki7JjcCpqjo86bFMwB9V1eXAdcDtbRp23TPuWlKbc34A+GpVfWvS4xm3qnoNOARcO+GhjMNVwEfb/PPXgauT/MtkhzQeVXWifT8F/CtwxWRHNBzGXYtqf1jcDxypqi9MejzjkmQqyZa2/E7mP5fgvyY6qDGoqruqantVTTP/L0Meq6q/nPCwRi7J+e2GAZKcD/wp0MVdccZ9AEm+Bvwn8IEkx5PsmvSYxuAq4Dbmr+CebV/XT3pQY7AVOJTkeeb/T9IjVbVhbgvcgC4CHk/yHPAU8HBV/duExzQU3gopSR3yyl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOvR/hmZVs8CdywQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sample3[:,0]+np.log(np.sqrt((k1*k2)*2/(k2+k1))),bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "diverse-brother",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009896824611116316"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def f(p):\n",
    "    return p**100\n",
    "\n",
    "x=np.arange(0,1,0.001)\n",
    "x+= x[1]/2\n",
    "np.sum(f(x)/x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "pleasant-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "# def sample():\n",
    "#     X1=np.random.randn(300,1)\n",
    "#     X2=np.random.randn(300,1)+0.\n",
    "#     features=np.concatenate([X1,X2])#.reshape(-1,1)\n",
    "#     target= np.concatenate([np.zeros_like(X1[:,0]),np.ones_like(X2[:,0])])\n",
    "#     xt,x0,_=rate_all_splits(features,target)\n",
    "\n",
    "#     return xt-x0\n",
    "# np.exp(sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "italic-framework",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.5236660500595463,\n",
       " [Splitpoint(stat=-3.7666412197213504, point=-3.76625240735568, idxpoint=0, idx_feature=2, counts=[30000, 29991, 30000, 30000], total_stat=0),\n",
       "  Splitpoint(stat=-3.7079234071061364, point=3.796696497620582, idxpoint=0, idx_feature=1, counts=[2, 0, 30000, 30000], total_stat=0),\n",
       "  Splitpoint(stat=-3.198697379739315, point=2.9927841316439108, idxpoint=0, idx_feature=0, counts=[59, 28, 30000, 30000], total_stat=0)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1=np.random.randn(30000,3)-0.0\n",
    "X2=np.random.randn(30000,3)+0.0\n",
    "features=np.concatenate([X1,X2])#.reshape(-1,1)\n",
    "target= np.concatenate([np.zeros_like(X1[:,0]),np.ones_like(X2[:,0])])\n",
    "\n",
    "rate_all_splits(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-playing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "integral-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ll, ev, s=rate_split(features[:,1], target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "cordless-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loglik1, evidence1=rate_split(feature,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "female-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evidence0=logbeta(np.sum(target)+1, np.sum(1-target)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-metabolism",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "coordinate-chambers",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41178.217796328536"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(np.log(0.5) * 300 + np.log(0.5) * 300)-evidence0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "seeing-feelings",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loglik1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-113ec793da62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloglik1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mevidence1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loglik1' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "loglik1.max()-evidence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "distinguished-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "whole-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import collections\n",
    "INode=namedtuple('Node', ['feature','threshold','lc','rc','counts'],defaults=[-1,0,None,None,None])\n",
    "\n",
    "def serializer(obj):\n",
    "    if isinstance(obj, list):\n",
    "        return obj\n",
    "    if isinstance(obj,float) or isinstance(obj,np.float64):\n",
    "        return round(obj,3)\n",
    "    elif hasattr(obj,'__dict__'):\n",
    "        return vars(obj)\n",
    "    else:\n",
    "        str(obj)\n",
    "\n",
    "\n",
    "SplitProposal=namedtuple('SplitProposal', ['node','fidx','split','side'])\n",
    "feature_use_per_path=5\n",
    "class Node(object):\n",
    "    def __init__(self, feature=-1, threshold=0,lc=None, rc=None,counts=None,options=None, \n",
    "                 pval_threshold=0.01,\n",
    "                feature_use_per_path=3\n",
    "                ):\n",
    "        self.feature=feature\n",
    "        self.threshold=threshold\n",
    "        self.lc=lc \n",
    "        self.rc=rc\n",
    "        self.counts=counts\n",
    "        self.options = options\n",
    "        self.pval_threshold=pval_threshold\n",
    "        self.feature_use_per_path=feature_use_per_path\n",
    "    @staticmethod\n",
    "    def initialize_node(X,y, feature_use_per_path=3, pval_threshold=1):\n",
    "#         splits=[(i,kssplitter(*featuretarget_to_twosample(a, y))) for (i,a) in enumerate(X)]\n",
    "#         splits=sorted([s for s in splits],key=lambda x: x[1].pvalue)\n",
    "        \n",
    "# #         splits2 = sorted([s for s in splits if s[1].pvalue < pval_threshold],key=lambda x: x[1].pvalue)\n",
    "        \n",
    "#         split = splits[0]\n",
    "        evidence, splits=rate_all_splits(X,y)\n",
    "        split=splits[-1]\n",
    "        return Node(split.idx_feature, split.point,counts=split.counts,feature_use_per_path=feature_use_per_path, pval_threshold=pval_threshold)\n",
    "    def __repr__(self):\n",
    "        import json\n",
    "        return json.dumps(self.__dict__, default=serializer)\n",
    "    def to_json(self):\n",
    "        import json\n",
    "        return json.dumps(self.__dict__, default=serializer)\n",
    "    \n",
    "    def options_to_consider(self, X: np.ndarray, y: np.ndarray, pruned_features=None):\n",
    "        if pruned_features==None:\n",
    "            pruned_features=[]\n",
    "        pruned_features = pruned_features+ [self.feature]\n",
    "        c=dict(collections.Counter(pruned_features))\n",
    "        feature = X[:,self.feature]\n",
    "        f = feature > self.threshold\n",
    "        total_splits=[]\n",
    "        changes_done=False\n",
    "        if self.lc is None and np.sum(~f)>2:\n",
    "            evidence, splits=rate_all_splits(X[~f], y[~f])\n",
    "            splits = [s for s in splits if s.idx_feature not in c or c[s.idx_feature] < self.feature_use_per_path]\n",
    "            if evidence > self.pval_threshold and len(splits)>0:\n",
    "                split=splits[-1]\n",
    "                self.lc = Node(split.idx_feature, split.point,counts=split.counts,feature_use_per_path=feature_use_per_path, pval_threshold=self.pval_threshold)\n",
    "                changes_done = True\n",
    "#             splits=[SplitProposal(self,i,kssplitter(*featuretarget_to_twosample(X[i,~f], y[~f])),'l') \n",
    "#                     for i in range(X.shape[0])\n",
    "#                     if (i not in c or c[i]< self.feature_use_per_path)\n",
    "#                    ]\n",
    "#             total_splits+= [s for s in splits if s.split.pvalue < self.pval_threshold]\n",
    "        else:\n",
    "            if np.sum(~f)>2:\n",
    "                changes_done = changes_done or self.lc.options_to_consider(X[~f],y[~f],pruned_features )\n",
    "        if self.rc is None and np.sum(f)>2:\n",
    "            \n",
    "            evidence, splits=rate_all_splits(X[f], y[f])\n",
    "            splits = [s for s in splits if s.idx_feature not in c or c[s.idx_feature] < self.feature_use_per_path]\n",
    "            if evidence > self.pval_threshold and len(splits)>0:\n",
    "                split=splits[-1]\n",
    "                self.rc = Node(split.idx_feature, split.point,counts=split.counts,feature_use_per_path=feature_use_per_path, pval_threshold=self.pval_threshold)\n",
    "                changes_done = True\n",
    "        else:\n",
    "            \n",
    "            if np.sum(f)>2:\n",
    "                changes_done = changes_done or self.rc.options_to_consider(X[f],y[f],pruned_features )\n",
    "        return changes_done\n",
    "        #,key=lambda x: x[1].pvalue)\n",
    "            \n",
    "    def apply_proposal(self, proposal:SplitProposal):\n",
    "        if proposal.side == 'r':\n",
    "            self.rc = Node(proposal.fidx, proposal.split.point, None, None, proposal.split.counts)\n",
    "#             self.rc = Node(proposal.fidx, proposal.split.adjusted_split_point, None, None, proposal.split.counts2)\n",
    "            \n",
    "        if proposal.side == 'l':\n",
    "            self.lc = Node(proposal.fidx, proposal.split.point, None, None, proposal.split.counts)\n",
    "#             self.lc = Node(proposal.fidx, proposal.split.adjusted_split_point, None, None, proposal.split.counts2)\n",
    "            \n",
    "    def iterate_fit(self,X,y):\n",
    "        return self.options_to_consider(X,y)\n",
    "    def predict(self, features):\n",
    "        feature = features[:,self.feature]\n",
    "        c= self.counts\n",
    "        proba_right = (1+c[1])/(2+c[0]+c[1])\n",
    "        proba_left = (1+c[3]-c[1])/(2+c[3]-c[1]+c[2]-c[0])\n",
    "#         print(proba_left, proba_right)\n",
    "        f = feature > self.threshold\n",
    "        result = np.zeros(f.shape[0])\n",
    "        if self.rc is None:\n",
    "            result[f] = proba_right\n",
    "        else:\n",
    "            result[f]=self.rc.predict(features[f])\n",
    "            \n",
    "        if self.lc is None:\n",
    "            result[~f] = proba_left\n",
    "        else:\n",
    "            result[~f]=self.lc.predict(features[~f])\n",
    "        return result\n",
    "     \n",
    "class KSModel(object):\n",
    "    def __init__(self, feature_use_per_path=3, pval_threshold=0.01):\n",
    "        self.n=None\n",
    "        self.pval_threshold=pval_threshold\n",
    "        self.feature_use_per_path=feature_use_per_path\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        n=Node.initialize_node(X,y, feature_use_per_path=self.feature_use_per_path,pval_threshold=self.pval_threshold)\n",
    "        while n.iterate_fit(X,y):\n",
    "            \n",
    "            pass\n",
    "        self.n = n\n",
    "    def predict(self,X):\n",
    "        return self.n.predict(X)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "shaped-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train.iloc[:,0:f].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "amazing-sherman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7857142857142857 0.7350970017636684\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.read_csv('/home/krystian/dane/data/sonar.all-data',header=None)\n",
    "\n",
    "f= 60\n",
    "df2=df.sample(frac=1,replace=False)\n",
    "df2[f]=  (df2[f]=='M')*1\n",
    "train=df2.iloc[0:100]\n",
    "test=df2.iloc[100:]\n",
    "\n",
    "\n",
    "\n",
    "dec=DecisionTreeClassifier(min_samples_leaf=10)\n",
    "dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "p=dec.predict_proba(test.iloc[:,0:f].values)[:,1]\n",
    "x1=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "\n",
    "dec=KSModel(pval_threshold=0.)\n",
    "dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "p=dec.predict(test.iloc[:,0:f].values)\n",
    "x2=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "print(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "vulnerable-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df=pd.read_csv('/home/krystian/dane/data/data_banknote_authentication.txt',header=None)\n",
    "\n",
    "def trial():\n",
    "    f= 4\n",
    "    df2=df.sample(frac=1,replace=False)\n",
    "    # df2[f]=  (df2[f]=='M')*1\n",
    "    train=df2.iloc[0:200]\n",
    "    test=df2.iloc[200:]\n",
    "\n",
    "    dec=DecisionTreeClassifier( max_depth=4)\n",
    "    dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "    p=dec.predict_proba(test.iloc[:,0:f].values)[:,1]\n",
    "    x1=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "    t1= np.mean(test.iloc[:,f].values==((p>0.5)*1))\n",
    "    # dec=xgboost.XGBRFClassifier()\n",
    "    # dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "    # p=dec.predict_proba(test.iloc[:,0:f].values)[:,1]\n",
    "    # x3=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "\n",
    "    dec=KSModel(pval_threshold=-0.5)\n",
    "    dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "    p=dec.predict(test.iloc[:,0:f].values)\n",
    "    x2=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "    \n",
    "    t2= np.mean(test.iloc[:,f].values==((p>0.5)*1))\n",
    "    return x1,t1,x2,t2\n",
    "\n",
    "trials=[trial() for x in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "thick-given",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.95099574, 0.93536689, 0.94957729, 0.92591297]),\n",
       " array([0.01743382, 0.01943834, 0.0190511 , 0.01941199]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "trials=np.array(trials)\n",
    "np.mean(trials,axis=0), np.std(trials, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "knowing-listening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df=pd.read_csv('/home/krystian/dane/data/sonar.all-data',header=None)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "joined-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv('/home/krystian/dane/data/sonar.all-data',header=None)\n",
    "\n",
    "def trial():\n",
    "    f= 60\n",
    "    df2=df.sample(frac=1,replace=False)\n",
    "    df2[f]=  (df2[f]=='M')*1\n",
    "    train=df2.iloc[0:100]\n",
    "    test=df2.iloc[100:]\n",
    "\n",
    "\n",
    "\n",
    "    dec=DecisionTreeClassifier(min_samples_leaf=10)\n",
    "    dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "    p=dec.predict_proba(test.iloc[:,0:f].values)[:,1]\n",
    "    x1=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "\n",
    "    dec=KSModel(pval_threshold=0.1)\n",
    "    dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "    p=dec.predict(test.iloc[:,0:f].values)\n",
    "    x2=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "    return x1,x2\n",
    "\n",
    "trials=np.array([trial() for _ in range(50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "graphic-seeking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.75506847, 0.73644532]), array([0.04625768, 0.05451641]))"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "trials=np.array(trials)\n",
    "np.mean(trials,axis=0), np.std(trials, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "derived-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df=pd.read_csv('/home/krystian/dane/data/pima-indians-diabetes.csv',header=None)\n",
    "\n",
    "def trial():\n",
    "    f= 8\n",
    "    df2=df.sample(frac=1,replace=False)\n",
    "    # df2[f]=  (df2[f]=='M')*1\n",
    "    train=df2.iloc[0:400]\n",
    "    test=df2.iloc[400:]\n",
    "\n",
    "    dec=DecisionTreeClassifier( max_depth=5,)\n",
    "    dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "    p=dec.predict_proba(test.iloc[:,0:f].values)[:,1]\n",
    "    x1=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "\n",
    "    # dec=xgboost.XGBRFClassifier()\n",
    "    # dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "    # p=dec.predict_proba(test.iloc[:,0:f].values)[:,1]\n",
    "    # x3=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "\n",
    "    dec=KSModel(pval_threshold=0.01)\n",
    "    dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "    p=dec.predict(test.iloc[:,0:f].values)\n",
    "    x2=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "    return x1,x2\n",
    "\n",
    "trials=[trial() for x in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "still-savings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.74192591, 0.77311101]), array([0.03199689, 0.024092  ]))"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "trials=np.array(trials)\n",
    "np.mean(trials,axis=0), np.std(trials, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "organized-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv('/home/krystian/dane/data/ionosphere.data',header=None)\n",
    "specs = [dict(max_depth=3),dict(max_depth=5),dict(max_depth=6), dict(max_depth=8),dict(min_samples_leaf=10),\n",
    "        dict(max_depth=5, criterion='entropy'),dict(min_samples_leaf=50),dict(min_weight_fraction_leaf=0.01),dict()\n",
    "        ]\n",
    "results = []\n",
    "f=34\n",
    "for i in range(100):\n",
    "    df2=df.sample(frac=1,replace=False)\n",
    "    df2[f]=  (df2[f]=='g')*1\n",
    "    train=df2.iloc[0:100]\n",
    "    test=df2.iloc[100:]\n",
    "    for s in specs:\n",
    "        dec=DecisionTreeClassifier( **s)\n",
    "        dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "        p=dec.predict_proba(test.iloc[:,0:f].values)[:,1]\n",
    "        x1=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "        \n",
    "        results.append((str(s),x1))\n",
    "\n",
    "    # dec=xgboost.XGBRFClassifier()\n",
    "    # dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "    # p=dec.predict_proba(test.iloc[:,0:f].values)[:,1]\n",
    "    # x3=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "\n",
    "    dec=KSModel(pval_threshold=-0.5)\n",
    "    dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "    p=dec.predict(test.iloc[:,0:f].values)\n",
    "    x2=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "    results.append((\"bayes-0.5\",x2))\n",
    "    \n",
    "    dec=KSModel(pval_threshold=0)\n",
    "    dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "    p=dec.predict(test.iloc[:,0:f].values)\n",
    "    x2=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "    results.append((\"bayes-0\",x2))\n",
    "    \n",
    "    dec=KSModel(pval_threshold=0.5)\n",
    "    dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "    p=dec.predict(test.iloc[:,0:f].values)\n",
    "    x2=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "    results.append((\"bayes+0.5\",x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "formed-gossip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bayes+0.5                                   0.841965\n",
       "bayes-0                                     0.853344\n",
       "bayes-0.5                                   0.858897\n",
       "{'max_depth': 3}                            0.837639\n",
       "{'max_depth': 5, 'criterion': 'entropy'}    0.836639\n",
       "{'max_depth': 5}                            0.836271\n",
       "{'max_depth': 6}                            0.839876\n",
       "{'max_depth': 8}                            0.839026\n",
       "{'min_samples_leaf': 10}                    0.881267\n",
       "{'min_samples_leaf': 50}                    0.626262\n",
       "{'min_weight_fraction_leaf': 0.01}          0.839835\n",
       "{}                                          0.840694\n",
       "dtype: float64"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "s=pd.Series([r[1] for r in results],[r[0]for  r in results])\n",
    "s.groupby(s.index).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "defensive-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv('/home/krystian/dane/data/pima-indians-diabetes.csv',header=None)\n",
    "def test_dataset(df, f,preproc=lambda x:x):\n",
    "    specs = [dict(max_depth=3),dict(max_depth=5),dict(max_depth=6), dict(max_depth=8),dict(min_samples_leaf=10),\n",
    "            dict(max_depth=5, criterion='entropy'),dict(min_samples_leaf=50),dict(min_weight_fraction_leaf=0.01),dict()\n",
    "            ]\n",
    "    specs = [dict(max_depth=3),dict(max_depth=5),dict(max_depth=6), dict(max_depth=8),dict(min_samples_leaf=10),\n",
    "            dict(max_depth=5, criterion='entropy'),dict(min_samples_leaf=50),dict(min_weight_fraction_leaf=0.01),dict(),\n",
    "             dict(min_samples_leaf=5),dict(min_samples_leaf=20),dict(min_samples_leaf=10,criterion='entropy')\n",
    "            ]\n",
    "    results = []\n",
    "    for i in range(100):\n",
    "        df2=df.sample(frac=1,replace=False)\n",
    "        df2=preproc(df2)\n",
    "    #     df2[f]=  (df2[f]=='g')*1\n",
    "        split = int(df2.shape[0]*0.9)\n",
    "        train=df2.iloc[0:split]\n",
    "        test=df2.iloc[split:]\n",
    "        for s in specs:\n",
    "            dec=DecisionTreeClassifier( **s)\n",
    "            dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "            p=dec.predict_proba(test.iloc[:,0:f].values)[:,1]\n",
    "            x1=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "            t1= np.mean(test.iloc[:,f].values==((p>0.5)*1))\n",
    "            results.append((str(s),x1,t1))\n",
    "\n",
    "        # dec=xgboost.XGBRFClassifier()\n",
    "        # dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "        # p=dec.predict_proba(test.iloc[:,0:f].values)[:,1]\n",
    "        # x3=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "\n",
    "\n",
    "        dec=KSModel(pval_threshold=-0.5)\n",
    "        dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "        p=dec.predict(test.iloc[:,0:f].values)\n",
    "        x2=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "        t1= np.mean(test.iloc[:,f].values==((p>0.5)*1))\n",
    "        results.append((\"bayes-0.5\",x2,t1))\n",
    "\n",
    "        dec=KSModel(pval_threshold=0)\n",
    "        dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "        p=dec.predict(test.iloc[:,0:f].values)\n",
    "        x2=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "        t1= np.mean(test.iloc[:,f].values==((p>0.5)*1))\n",
    "        results.append((\"bayes-0\",x2,t1))\n",
    "\n",
    "        dec=KSModel(pval_threshold=0.5)\n",
    "        dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "        p=dec.predict(test.iloc[:,0:f].values)\n",
    "        x2=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "        t1= np.mean(test.iloc[:,f].values==((p>0.5)*1))\n",
    "        results.append((\"bayes+0.5\",x2,t1))\n",
    "        \n",
    "    s=pd.Series([r[1] for r in results],[r[0]for  r in results])\n",
    "    print(\"ROC\")\n",
    "    print(s.groupby(s.index).mean())\n",
    "    \n",
    "    print(\"accuracy\")\n",
    "    s=pd.Series([r[2] for r in results],[r[0]for  r in results])\n",
    "    print(s.groupby(s.index).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "boolean-runner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC\n",
      "bayes+0.5                                           0.634503\n",
      "bayes-0                                             0.639778\n",
      "bayes-0.5                                           0.639276\n",
      "{'max_depth': 3}                                    0.631610\n",
      "{'max_depth': 5, 'criterion': 'entropy'}            0.620213\n",
      "{'max_depth': 5}                                    0.618690\n",
      "{'max_depth': 6}                                    0.614625\n",
      "{'max_depth': 8}                                    0.602749\n",
      "{'min_samples_leaf': 10, 'criterion': 'entropy'}    0.660621\n",
      "{'min_samples_leaf': 10}                            0.662236\n",
      "{'min_samples_leaf': 20}                            0.669030\n",
      "{'min_samples_leaf': 50}                            0.668531\n",
      "{'min_samples_leaf': 5}                             0.632719\n",
      "{'min_weight_fraction_leaf': 0.01}                  0.592998\n",
      "{}                                                  0.564127\n",
      "dtype: float64\n",
      "accuracy\n",
      "bayes+0.5                                           0.724516\n",
      "bayes-0                                             0.722903\n",
      "bayes-0.5                                           0.731613\n",
      "{'max_depth': 3}                                    0.743226\n",
      "{'max_depth': 5, 'criterion': 'entropy'}            0.728065\n",
      "{'max_depth': 5}                                    0.725484\n",
      "{'max_depth': 6}                                    0.707097\n",
      "{'max_depth': 8}                                    0.684194\n",
      "{'min_samples_leaf': 10, 'criterion': 'entropy'}    0.720323\n",
      "{'min_samples_leaf': 10}                            0.726129\n",
      "{'min_samples_leaf': 20}                            0.733548\n",
      "{'min_samples_leaf': 50}                            0.712258\n",
      "{'min_samples_leaf': 5}                             0.691935\n",
      "{'min_weight_fraction_leaf': 0.01}                  0.672581\n",
      "{}                                                  0.659032\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preproc_haberman(df2):\n",
    "    df2[3] = (df2[3]==2)*1\n",
    "    return df2\n",
    "test_dataset(pd.read_csv(\"/home/krystian/dane/data/haberman.data\",header=None),3, preproc_haberman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = []\n",
    "f=8\n",
    "for i in range(100):\n",
    "    df2=df.sample(frac=1,replace=False)\n",
    "#     df2[f]=  (df2[f]=='g')*1\n",
    "    train=df2.iloc[0:100]\n",
    "    test=df2.iloc[100:]\n",
    "    for s in specs:\n",
    "        dec=DecisionTreeClassifier( **s)\n",
    "        dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "        p=dec.predict_proba(test.iloc[:,0:f].values)[:,1]\n",
    "        x1=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "        results.append((str(s),x1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "moderate-embassy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bayes+0.5                                           0.772759\n",
       "bayes-0                                             0.776541\n",
       "bayes-0.5                                           0.764065\n",
       "{'max_depth': 3}                                    0.760356\n",
       "{'max_depth': 5, 'criterion': 'entropy'}            0.752858\n",
       "{'max_depth': 5}                                    0.744437\n",
       "{'max_depth': 6}                                    0.723702\n",
       "{'max_depth': 8}                                    0.695288\n",
       "{'min_samples_leaf': 10, 'criterion': 'entropy'}    0.765208\n",
       "{'min_samples_leaf': 10}                            0.766376\n",
       "{'min_samples_leaf': 20}                            0.784504\n",
       "{'min_samples_leaf': 50}                            0.774158\n",
       "{'min_samples_leaf': 5}                             0.733458\n",
       "{'min_weight_fraction_leaf': 0.01}                  0.721964\n",
       "{}                                                  0.665721\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "s=pd.Series([r[1] for r in results],[r[0]for  r in results])\n",
    "s.groupby(s.index).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "incorporate-disposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bayes+0.5                                           0.736033\n",
       "bayes-0                                             0.735951\n",
       "bayes-0.5                                           0.711685\n",
       "{'max_depth': 3}                                    0.725054\n",
       "{'max_depth': 5, 'criterion': 'entropy'}            0.722418\n",
       "{'max_depth': 5}                                    0.720897\n",
       "{'max_depth': 6}                                    0.713777\n",
       "{'max_depth': 8}                                    0.703261\n",
       "{'min_samples_leaf': 10, 'criterion': 'entropy'}    0.726766\n",
       "{'min_samples_leaf': 10}                            0.726005\n",
       "{'min_samples_leaf': 20}                            0.737174\n",
       "{'min_samples_leaf': 50}                            0.729592\n",
       "{'min_samples_leaf': 5}                             0.708043\n",
       "{'min_weight_fraction_leaf': 0.01}                  0.706957\n",
       "{}                                                  0.694484\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "s=pd.Series([r[2] for r in results],[r[0]for  r in results])\n",
    "s.groupby(s.index).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "painful-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv('/home/krystian/dane/data/sonar.all-data',header=None)\n",
    "specs = [dict(max_depth=3),dict(max_depth=5),dict(max_depth=6), dict(max_depth=8),dict(min_samples_leaf=10),\n",
    "        dict(max_depth=5, criterion='entropy'),dict(min_samples_leaf=50),dict(min_weight_fraction_leaf=0.01),dict()\n",
    "        ]\n",
    "results = []\n",
    "f=60\n",
    "for i in range(100):\n",
    "    df2=df.sample(frac=1,replace=False)\n",
    "    df2[f]=  (df2[f]=='M')*1\n",
    "    train=df2.iloc[0:100]\n",
    "    test=df2.iloc[100:]\n",
    "    for s in specs:\n",
    "        dec=DecisionTreeClassifier( **s)\n",
    "        dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "        p=dec.predict_proba(test.iloc[:,0:f].values)[:,1]\n",
    "        x1=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "        results.append((str(s),x1))\n",
    "    dec=KSModel(pval_threshold=-0.5)\n",
    "    dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "    p=dec.predict(test.iloc[:,0:f].values)\n",
    "    x2=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "    results.append((\"bayes-0.5\",x2))\n",
    "    \n",
    "    dec=KSModel(pval_threshold=0)\n",
    "    dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "    p=dec.predict(test.iloc[:,0:f].values)\n",
    "    x2=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "    results.append((\"bayes-0\",x2))\n",
    "    \n",
    "    dec=KSModel(pval_threshold=0.5)\n",
    "    dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "    p=dec.predict(test.iloc[:,0:f].values)\n",
    "    x2=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "    results.append((\"bayes+0.5\",x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "adverse-catch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bayes+0.5                                   0.725976\n",
       "bayes-0                                     0.754111\n",
       "bayes-0.5                                   0.755097\n",
       "{'max_depth': 3}                            0.713981\n",
       "{'max_depth': 5, 'criterion': 'entropy'}    0.717318\n",
       "{'max_depth': 5}                            0.701225\n",
       "{'max_depth': 6}                            0.696988\n",
       "{'max_depth': 8}                            0.701355\n",
       "{'min_samples_leaf': 10}                    0.755830\n",
       "{'min_samples_leaf': 50}                    0.674040\n",
       "{'min_weight_fraction_leaf': 0.01}          0.695126\n",
       "{}                                          0.697087\n",
       "dtype: float64"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "s=pd.Series([r[1] for r in results],[r[0]for  r in results])\n",
    "s.groupby(s.index).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "uniform-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df=pd.read_csv('/home/krystian/dane/data/data_banknote_authentication.txt',header=None)\n",
    "f=4\n",
    "specs = [dict(max_depth=3),dict(max_depth=5),dict(max_depth=6), dict(max_depth=8),dict(min_samples_leaf=10),\n",
    "        dict(max_depth=5, criterion='entropy'),dict(min_samples_leaf=50),dict(min_weight_fraction_leaf=0.01),dict()\n",
    "        ]\n",
    "results = []\n",
    "for i in range(100):\n",
    "    df2=df.sample(frac=1,replace=False)\n",
    "    # df2[f]=  (df2[f]=='M')*1\n",
    "    train=df2.iloc[0:400]\n",
    "    test=df2.iloc[400:]\n",
    "    for s in specs:\n",
    "        dec=DecisionTreeClassifier( **s)\n",
    "        dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "        p=dec.predict_proba(test.iloc[:,0:f].values)[:,1]\n",
    "        x1=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "        results.append((str(s),x1))\n",
    "    dec=KSModel(pval_threshold=-0.5)\n",
    "    dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "    p=dec.predict(test.iloc[:,0:f].values)\n",
    "    x2=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "    results.append((\"bayes-0.5\",x2))\n",
    "    \n",
    "    dec=KSModel(pval_threshold=0)\n",
    "    dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "    p=dec.predict(test.iloc[:,0:f].values)\n",
    "    x2=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "    results.append((\"bayes-0\",x2))\n",
    "    \n",
    "    dec=KSModel(pval_threshold=0.5)\n",
    "    dec.fit(train.iloc[:,0:f].values, train.iloc[:,f].values)\n",
    "    p=dec.predict(test.iloc[:,0:f].values)\n",
    "    x2=(roc_auc_score(test.iloc[:,f].values,p))\n",
    "    results.append((\"bayes+0.5\",x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "artistic-lending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bayes+0.5                                   0.964114\n",
       "bayes-0                                     0.968832\n",
       "bayes-0.5                                   0.970291\n",
       "{'max_depth': 3}                            0.956159\n",
       "{'max_depth': 5, 'criterion': 'entropy'}    0.973588\n",
       "{'max_depth': 5}                            0.969243\n",
       "{'max_depth': 6}                            0.967171\n",
       "{'max_depth': 8}                            0.965945\n",
       "{'min_samples_leaf': 10}                    0.969907\n",
       "{'min_samples_leaf': 50}                    0.935135\n",
       "{'min_weight_fraction_leaf': 0.01}          0.971665\n",
       "{}                                          0.966009\n",
       "dtype: float64"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "s=pd.Series([r[1] for r in results],[r[0]for  r in results])\n",
    "s.groupby(s.index).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-appreciation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
